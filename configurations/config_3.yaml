general:
    dataset_root: "datasets/sr_10_40"
    partition: "train"
    seed: 2
    relaxation: "lukasiewicz"
    run_eval_mode: False

training:
    epochs: 1
    batch_size: 64
    shuffle: True
    num_workers: 8
    use_cuda: True
    optimizer:
        scheduler_steps: 900
        step_rule: "AdamW"
        learning_rate: 0.003 # LR Finder suggestions: 2e-3, 3e-3
        clip_grad_norm: 5.00
        weight_decay: 0.0001
    sat_loss_a: 1.0
    assn_loss_a: 1.0
   
logging:
    save_checkpoint: True # save a checkpoint every epoch
    experiment_tag: 'sr_10_40_train_lukasiewicz'
    load_checkpoint: False # use a saved checkpoint
    resume_training: True # if false, discard everything except model weights
    load_from_tag: 'your_previous_experiment_model' # if you want to load from prev experiment

model:
    xavier_init: False
    embedding_dim: 128
    mlp_hidden_layers: 3
    mlp_activation: "relu"
    mlp_dropout: 0.0
    lstm_iters: 26
    lstm_activation: "tanh"
    lstm_dropout: 0.0
    use_attention: False
    attention_nheads: 8
    attention_pdrop: 0.0
    attention_resid_pdrop: 0.0

